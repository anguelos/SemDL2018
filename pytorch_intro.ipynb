{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Requirements\n",
    "```bash\n",
    "pip install --user ipywidgets torchvision tqdm matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "try:\n",
    "    from tqdm import tqdm as iter_progress\n",
    "except:\n",
    "    iter_progress=lambda x:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have we got GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU works\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"CPU will have to do\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "transform_test = transform_train\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2096, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2096, shuffle=False, num_workers=5)\n",
    "\n",
    "images, labels = iter(testloader).next()\n",
    "img=torchvision.utils.make_grid(images[:32,:,:,:]).numpy()\n",
    "plt.imshow(img.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, (5,5))\n",
    "        self.conv2 = torch.nn.Conv2d(6, 10, (5,5))\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = torch.nn.Linear(160, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc_class = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        layer1_activations=torch.tanh(self.conv1(X))\n",
    "        layer2_activations=self.pool(layer1_activations)\n",
    "        layer3_activations=torch.tanh(self.conv2(layer2_activations))\n",
    "        layer4_activations=self.pool(layer3_activations)\n",
    "        layer4_activations=layer4_activations.view([layer4_activations.size()[0],160])\n",
    "        layer5_activations=torch.tanh(self.fc1(layer4_activations))\n",
    "        layer6_activations=torch.tanh(self.fc2(layer5_activations))\n",
    "        output_logits = self.fc_class(layer6_activations)\n",
    "        return output_logits\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.load_state_dict(torch.load(filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define iterating over a single epoch\n",
    "(For train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(net,dataloader,criterion,device,optimizer=None):\n",
    "    net.train()\n",
    "    accumulated_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(iter_progress(dataloader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        if optimizer:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        accumulated_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return correct,total,accumulated_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Lenet5()\n",
    "net.cpu()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "train_performance = []\n",
    "validation_performance = []\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_correct,train_total,train_loss=run_epoch(net, trainloader, criterion, 'cpu', optimizer)\n",
    "    train_err=1-float(train_correct)/train_total\n",
    "    test_correct,test_total,test_error=run_epoch(net, testloader, criterion, 'cpu', None)\n",
    "    test_err=1-float(test_correct)/test_total\n",
    "    train_performance.append(train_err)\n",
    "    validation_performance.append(test_err)\n",
    "    print(\"Epoch: {} Train Error: {} Validation Error: {} Loss: {}\".format(epoch,train_err,test_err,train_loss))\n",
    "\n",
    "plt.semilogy(train_performance)\n",
    "plt.semilogy(validation_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save(\"lenet5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Lenet5()\n",
    "net.cpu()\n",
    "test_correct,test_total,test_error=run_epoch(net, testloader, criterion, 'cpu', None)\n",
    "test_err=1-float(test_correct)/test_total\n",
    "print(\"Initial test error {}\".format(test_err))\n",
    "net.load(\"lenet5.pt\")\n",
    "test_correct,test_total,test_error=run_epoch(net, testloader, criterion, 'cpu', None)\n",
    "test_err=1-float(test_correct)/test_total\n",
    "print(\"Resumed test error {}\".format(test_err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Lenet5()\n",
    "if device=='cuda':\n",
    "    net.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "train_performance = []\n",
    "validation_performance = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_correct,train_total,train_loss=run_epoch(net, trainloader, criterion, device, optimizer)\n",
    "    train_err=1-float(train_correct)/train_total\n",
    "    test_correct,test_total,test_error=run_epoch(net, testloader, criterion, device, None)\n",
    "    test_err=1-float(test_correct)/test_total\n",
    "    train_performance.append(train_err)\n",
    "    validation_performance.append(test_err)\n",
    "    print(\"Epoch: {} Train Error: {} Validation Error: {} Loss: {}\".format(epoch,train_err,test_err,train_loss))\n",
    "\n",
    "plt.semilogy(train_performance)\n",
    "plt.semilogy(validation_performance)\n",
    "plt.legend(['train error','test error'])\n",
    "mnist_train_performance=train_performance\n",
    "mnist_validation_performance=validation_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about a more difficult dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "transform_test = transform_train\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./fashion_data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2096, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./fashion_data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2096, shuffle=False, num_workers=5)\n",
    "\n",
    "images, labels = iter(testloader).next()\n",
    "img=torchvision.utils.make_grid(images[:32,:,:,:]).numpy()*.3+.13\n",
    "plt.imshow(img.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on the same model for a harder problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Lenet5()\n",
    "if device=='cuda':\n",
    "    net.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "train_performance = []\n",
    "validation_performance = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_correct,train_total,train_loss=run_epoch(net, trainloader, criterion, device, optimizer)\n",
    "    train_err=1-float(train_correct)/train_total\n",
    "    test_correct,test_total,test_error=run_epoch(net, testloader, criterion, device, None)\n",
    "    test_err=1-float(test_correct)/test_total\n",
    "    train_performance.append(train_err)\n",
    "    validation_performance.append(test_err)\n",
    "    print(\"Epoch: {} Train Error: {} Validation Error: {} Loss: {}\".format(epoch,train_err,test_err,train_loss))\n",
    "\n",
    "plt.semilogy(train_performance)\n",
    "plt.semilogy(validation_performance)\n",
    "plt.semilogy(mnist_train_performance)\n",
    "plt.semilogy(mnist_validation_performance)\n",
    "plt.legend(['Fashion train error','Fashion test error','MNIST train error','MNIST test error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorCNN(torch.nn.Module):\n",
    "    def __init__(self,filename=\"\",input_size=(32,32,3)):\n",
    "        super(ColorCNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, (3, 3))\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, (3, 3))\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(16,32, (3, 3))\n",
    "        self.conv4 = torch.nn.Conv2d(32, 32, (3, 3))\n",
    "        \n",
    "        activation_width = lambda x: (((x-4)/2)-4)/2\n",
    "        activation_height = lambda x: (((x-4)/2)-4)/2\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.dropout2d = torch.nn.Dropout2d(p=0.1)\n",
    "        self.dropout_fc = torch.nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.last_conv_size=activation_width(input_size[0])*activation_height(input_size[1])*int(self.conv4.bias.shape[0])\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(self.last_conv_size, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc_class = torch.nn.Linear(128, 10)\n",
    "        \n",
    "                \n",
    "    def forward(self,X):\n",
    "        layer1_activations=self.dropout2d( F.relu(self.conv1(X)))\n",
    "        layer2_activations=self.dropout2d( F.relu(self.conv2(layer1_activations)))\n",
    "        layer3_activations=self.pool(layer2_activations)\n",
    "\n",
    "        layer4_activations=self.dropout2d( F.relu(self.conv3(layer3_activations)))\n",
    "        layer5_activations=self.dropout2d( F.relu(self.conv4(layer4_activations)))\n",
    "        layer6_activations=self.pool(layer5_activations)\n",
    "\n",
    "        layer7_activations=layer6_activations.view([layer6_activations.size()[0], self.last_conv_size])\n",
    "        layer7_activations=self.dropout_fc(F.relu(self.fc1(layer7_activations)))\n",
    "        layer8_activations=self.dropout_fc(F.relu(self.fc2(layer7_activations)))\n",
    "        output_logits=self.fc_class(layer8_activations)\n",
    "        \n",
    "        return output_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a harder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "images, labels = iter(testloader).next()\n",
    "img=torchvision.utils.make_grid(images[:32,:,:,:]).numpy() / 2 + 0.5\n",
    "plt.imshow(img.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the larger network on the hardest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ColorCNN()\n",
    "if device=='cuda':\n",
    "    net.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "train_performance = []\n",
    "validation_performance = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_correct,train_total,train_loss=run_epoch(net, trainloader, criterion, device, optimizer)\n",
    "    train_err=1-float(train_correct)/train_total\n",
    "    test_correct,test_total,test_error=run_epoch(net, testloader, criterion, device, None)\n",
    "    test_err=1-float(test_correct)/test_total\n",
    "    train_performance.append(train_err)\n",
    "    validation_performance.append(test_err)\n",
    "    print(\"Epoch: {} Train Error: {} Validation Error: {} Loss: {}\".format(epoch,train_err,test_err,train_loss))\n",
    "\n",
    "plt.plot(train_performance)\n",
    "plt.plot(test_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tensofows ploting in pytorch\n",
    "\n",
    "#### Install tensorboardX and tensorflow\n",
    "```bash\n",
    "pip install --user tensorboardX tensorflow\n",
    "```\n",
    "\n",
    "#### Run tensorboard \n",
    "```bash\n",
    "tensorboard --logdir runs/*/\n",
    "```\n",
    "\n",
    "#### Open your browser\n",
    "\n",
    "http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboardX\n",
    "net=ColorCNN()\n",
    "if device=='cuda':\n",
    "    net.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "train_performance = []\n",
    "validation_performance = []\n",
    "\n",
    "writer = tensorboardX.SummaryWriter()\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_correct,train_total,train_loss=run_epoch(net, trainloader, criterion, device, optimizer)\n",
    "    train_err=1-float(train_correct)/train_total\n",
    "    test_correct,test_total,test_loss=run_epoch(net, testloader, criterion, device, None)\n",
    "    test_err=1-float(test_correct)/test_total\n",
    "    \n",
    "    writer.add_scalar('error/train',train_err, epoch)\n",
    "    writer.add_scalar('error/test', test_err, epoch)\n",
    "    \n",
    "    writer.add_scalar('loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('loss/test', test_loss, epoch)\n",
    "    filter_image=(torchvision.utils.make_grid(net.conv1.weight).data.cpu()).numpy().transpose(1,2,0)\n",
    "    writer.add_image('filters/conv1',filter_image , epoch)\n",
    "    writer.add_text('text',\"Epoch: {} Train Error: {} Validation Error: {} Loss: {}\".format(epoch,train_err,test_err,train_loss),epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
